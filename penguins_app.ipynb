{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Streamlit Web App for the Penguins Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<streamlit.delta_generator.DeltaGenerator at 0x2284960b1c8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#headers in streamlit\n",
    "st.write(\"\"\"\n",
    "         #Penguin prediction app\n",
    "         This app predicts the palmer penguin species\n",
    "         \"\"\")\n",
    "\n",
    "st.sidebar.header('User Input Features')\n",
    "\n",
    "st.sidebar.markdown(\"\"\"\"Link to input file \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect user input features into a dataframe\n",
    "uploaded_file=st.sidebar.file_uploader(\"Upload your input CSV file\", type=[\"csv\"])\n",
    "if uploaded_file is not None:\n",
    "    input_df=pd.read_csv(uploaded_file)\n",
    "else:\n",
    "    def user_input_features():\n",
    "        island = st.sidebar.selectbox('Island',('Biscoe','Dream','Torgersen'))\n",
    "        sex = st.sidebar.selectbox('Sex',('male','female'))\n",
    "        bill_length_mm = st.sidebar.slider('Bill length (mm)', 32.1,59.6,43.9)\n",
    "        bill_depth_mm = st.sidebar.slider('Bill depth (mm)', 13.1,21.5,17.2)\n",
    "        flipper_length_mm = st.sidebar.slider('Flipper length (mm)', 172.0,231.0,201.0)\n",
    "        body_mass_g = st.sidebar.slider('Body mass (g)', 2700.0,6300.0,4207.0)\n",
    "        data = {'island': island,\n",
    "                'bill_length_mm': bill_length_mm,\n",
    "                'bill_depth_mm': bill_depth_mm,\n",
    "                'flipper_length_mm': flipper_length_mm,\n",
    "                'body_mass_g': body_mass_g,\n",
    "                'sex': sex}\n",
    "        features = pd.DataFrame(data, index=[0])\n",
    "        return features\n",
    "    input_df = user_input_features()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines user input features with entire penguins dataset\n",
    "# This will be useful for the encoding phase\n",
    "penguins_raw = pd.read_csv('C:/Users/abder/OneDrive/Documents/Education/Python/3. Machine Learning/Data_Penguin.csv')\n",
    "penguins = penguins_raw.drop(columns=['species'])\n",
    "df = pd.concat([input_df,penguins],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding of ordinal features\n",
    "# https://www.kaggle.com/pratik1120/penguin-dataset-eda-classification-and-clustering\n",
    "encode = ['sex','island']\n",
    "for col in encode:\n",
    "    dummy = pd.get_dummies(df[col], prefix=col)\n",
    "    df = pd.concat([df,dummy], axis=1)\n",
    "    del df[col]\n",
    "df = df[:1] # Selects only the first row (the user input data)\n",
    "\n",
    "# Displays the user input features\n",
    "st.subheader('User Input features')\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    st.write(df)\n",
    "else:\n",
    "    st.write('Awaiting CSV file to be uploaded. Currently using example input parameters (shown below).')\n",
    "    st.write(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in saved classification model\n",
    "load_clf = pickle.load(open('penguins_clf.pkl', 'rb'))\n",
    "\n",
    "# Apply model to make predictions\n",
    "prediction = load_clf.predict(df)\n",
    "prediction_proba = load_clf.predict_proba(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.subheader('Prediction')\n",
    "penguins_species = np.array(['Adelie','Chinstrap','Gentoo'])\n",
    "st.write(penguins_species[prediction])\n",
    "\n",
    "st.subheader('Prediction Probability')\n",
    "st.write(prediction_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
